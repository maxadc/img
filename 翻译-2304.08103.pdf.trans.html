<!DOCTYPE html><head><meta charset="utf-8"><title>翻译结果</title><style>
.row {
  display: flex;
  flex-wrap: wrap;
}

.column {
  flex: 1;
  padding: 10px;
}

.table-header {
  font-weight: bold;
  border-bottom: 1px solid black;
}

.table-row {
  border-bottom: 1px solid lightgray;
}

.table-cell {
  padding: 5px;
}
        </style></head>
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>论文概况</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>标题：Low-code LLM: Visual Programming over LLMs
收录会议或期刊：会议：软件工程年会；期刊：计算机科学
作者：Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang, Tao Ge, Chenfei Wu, Wang You, Ting Song, Yan Xia, Jonathan Tien, Nan Duan
摘要：本文介绍了一种名为Low-code LLM的人机界面交互框架，它集成了六种简单的低代码视觉编程交互方式，通过单击、拖动或文本编辑等方式支持，以实现更可控和稳定的响应。通过图形用户界面的可视化交互，用户无需编写 trivial Prompt，可以将自己的想法融入工作流程。文中提出的Low-code LLM框架包括一个规划LM，用于为复杂的任务设计 structured planning workflow，该 workflow 可经过低代码视觉编程操作由用户相应地进行编辑和确认，以及一个执行LM，在用户确认的 workflow 中生成响应。
编号：18
作者邮箱：[v-yuzhecai, shaoguang.mao, wenshan.wu, zehwang, yaobo.liang, tage, chewu, v-wangyou, tsong, yanxia, jtien, nanduan]@microsoft.com</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>二、论文翻译</p></div></div>
    <div class="column table-cell"><div class="markdown-body"></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>Low-code LLM: Visual Programming over LLMs </p>
<p>Yuzhe Cai*, Shaoguang Mao∗, Wenshan Wu∗, Zehua Wang∗, Yaobo Liang, Tao Ge Chenfei Wu, Wang You, Ting Song, Yan Xia†, Jonathan Tien, Nan Duan† Microsoft Research Asia {v-yuzhecai, shaoguang.mao, wenshan.wu, zehwang, yaobo.liang, tage, chewu, v-wangyou, tsong, yanxia, jtien, nanduan}@microsoft.com</p>
<p>Abstract </p>
<p>Effectively utilizing LLMs for complex tasks is challenging, often involving a time-consuming and uncontrollable prompt engineering process. This paper intro duces a novel human-LLM interaction framework, Low-code LLM. It incorporates six types of simple low-code visual programming interactions, all supported by clicking, dragging, or text editing, to achieve more controllable and stable re sponses. Through visual interaction with a graphical user interface, users can incorporate their ideas into the workﬂow without writing trivial prompts. The proposed Low-code LLM framework consists of a Planning LLM that designs a structured planning workﬂow for complex tasks, which can be correspondingly edited and conﬁrmed by users through low-code visual programming operations, and an Executing LLM that generates responses following the user-conﬁrmed work ﬂow. We highlight three advantages of the low-code LLM: controllable generation results, user-friendly human-LLM interaction, and broadly applicable scenarios. We demonstrate its beneﬁts using four typical applications. By introducing this approach, we aim to bridge the gap between humans and LLMs, enabling more effective and efﬁcient utilization of LLMs for complex tasks. Our system will besoon publicly available at LowCodeLLM.</p>
<p>Figure 1: Overview of the Low-code human-LLM interaction (Low-code LLM) and its comparison with the conventional interaction. The red arrow indicates the main human-model interaction loop. 1</p>
<p>1 Introduction </p>
<p>Large language models (LLMs), such as ChatGPT(OpenAI, 2022) and GPT-4(OpenAI, 2023), have garnered signiﬁcant interest from both academia and industry, as they demonstrate impressive capability across a range of tasks(Bubeck et al., 2023), and are increasingly utilized in a variety of other ﬁelds as well(Nori et al., 2023; Choi et al., 2023; Baidoo-Anu and Owusu Ansah, 2023). However, it is not yet perfect in handling complex tasks. For example, when generating a long paper, the presented arguments, supporting evidence, and overall structure may not always meet expectations in diverse user scenarios. Or, when serving as a task completion virtual assistant, ChatGPT may not always interact with users in the intended manner and may even display inappropriate behavior invarious business environments.</p>
<p>Effective utilization of LLMs like ChatGPT requires careful prompt engineering(Zhou et al., 2022). However, prompt engineering can be particularly challenging when instructing LLMs to perform complex tasks, as reﬂected in more uncontrollable responses and more time-consuming prompt reﬁning(Tan et al., 2023). There exists a gap between providing prompts and receiving responses,and the process of generating responses is not accessible to humans.</p>
<p>To reduce this gap, this paper proposes a new human-LLM interaction pattern Low-code LLM, which refers to the concept of low-code visual programming(Hirzel, 2022), like Visual Basic(Microsoft, 1991) or Scratch(Resnick et al., 2009). Users can conﬁrm the complex execution processes through six predeﬁned simple operations on an automatically generated workﬂow, such as adding or deleting,graphical dragging, and text editing.</p>
<p>As shown in Figure 1, human-LLM interaction can be completed by: (1) A Planning LLM that generates a highly structured workﬂow for complex tasks. (2) Users editing the workﬂow with predeﬁned low-code operations, which are all supported by clicking, dragging, or text editing. (3) An Executing LLM that generates responses with the reviewed workﬂow. (4) Users continuing to reﬁnethe workﬂow until satisfactory results are obtained.</p>
<p>We applied Low-code LLM to four types of complex tasks: long-content generation, large project deployment, task-completion virtual assistant, and knowledge embedded system. These examples demonstrate how the proposed framework assists users in easily controlling LLMs to complete complex tasks. Compared with the conventional human-LLM interaction pattern, Low-code LLM has the following advantages: 1. Controllable Generation. Complicated tasks are decomposed into structured conducting plans and presented to users as workﬂows. Users can control the LLMs’ execution through low-code operations to achieve more controllable responses. The responses generated followed the customizedworkﬂow will be more aligned with the user’s requirements.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>Low-code LLM: 图形编程优于语言模型</p>
<p>Yuzhe Cai*, Shaoguang Mao∗, Wenshan Wu∗, Zehua Wang∗, Yaobo Liang, Tao Ge Chenfei Wu, Wang You, Ting Song, Yan Xia†, Jonathan Tien, Nan Duan† Microsoft Research Asia {v-yuzhecai, shaoguang.mao, wenshan.wu, Zehwang, yaobo.liang, tage, chewu, v-wangyou, tsong,yanxia, jtien, nanduan}@microsoft.com</p>
<h1>摘要</h1>
<p>有效地利用语言模型协助复杂任务是一项具有挑战性的任务，通常会涉及复杂的 prompt 工程过程。本论文提出了一种低代码人类-语言模型相互作用框架，Low-code LLM，它包括六种简单的低代码视觉编程交互，所有都可以通过点击、拖动或文本编辑的支持，以获得更可控和稳定的响应。通过图形用户界面用户进行视觉交互，用户不需要编写 trivial 提示来实现将想法加入到流程中。该框架由规划语言模型设计一个结构紧凑的 planning workflow，该计划workflow 可以相应地进行编辑和确认，以及执行语言模型生成后续的响应。我们强调了 Low-code LLM的三个优点：可控的生成结果，用户友好的人类语言模型交互，以及更广泛的适用场景。我们采用了四个典型应用来证明其优点。通过这种方法，我们旨在 bridging the gap between humans and LLMs，使 LLMs 对复杂任务具有更有效和高效的利用。我们的系统在不久的将来将在 LowCodeLLM 上公钥授权发布。</p>
<p>图 1: Low-code LLM 与普通人类语言模型交互的比较和概述。红色箭头表示主要人类 - 模型交互循环。1</p>
<h1>1 引言</h1>
<p>大型语言模型 (LLMs)，如 ChatGPT(OpenAI,2022) 和 GPT-4(OpenAI,2023)，在学术界和工业界都引起了大量兴趣，因为它们在许多任务上都表现出了令人印象深刻的能力(Bubeck,2023)，并在各种其他领域都得到了广泛的应用(Nori,2023; Choi,2023; Baidoo-Anu，和 Owusu Ansah,2023)。但是，处理复杂任务仍未完全准备好，例如生成一篇长论文时，所呈现的观点、支持证据和整体结构可能在不同的用户场景中不够满意。或者，当作为任务完成虚拟助手时，ChatGPT 可能并不一定以预期的方式与用户互动，甚至可能在不同商业环境下表现出不良行为(ChatGPT 和 ChatGPT 的参考文献)。</p>
<p>为了更好地利用 ChatGPT(OpenAI,2022) 等语言模型，需要进行 careful prompt 工程(Zhou,2022)，而 prompt 工程在指示语言模型执行复杂任务时变得更加具有挑战性，因为提供更多和控制较少的响应可能导致更多的不可控响应和更耗时的改进(Tan,2023)。此外，提供提示和接收响应之间存在一个鸿沟，而生成响应的过程向人类是不可掌握的。</p>
<p>为了解决这些问题，本论文提出了一种低代码人类语言模型相互作用框架，Low-code LLM，它基于低代码视觉编程的概念(Hirzel,2022)，类似于 Visual Basic(Microsoft,1991) 或 Scratch(Resnick,2009)。用户可以通过在生成的计划工作流程上执行一系列默认简单的操作，以确认复杂执行流程，如添加或删除、图形拖动和文本编辑。</p>
<p>如图 1 所示，Low-code LLM 可以完成人类语言模型交互：(1)规划和结构紧凑的计划工作流程，(2)通过预先定义的低代码操作修改工作流，并且所有操作都支持点击、拖动或文本编辑，(3)由规划语言模型生成的生成结果，(4)继续对工作流程进行改进，直到得到令人满意的结果为止。</p>
<p>本论文还采用 Low-code LLM 对一些类型的复杂任务进行了应用：生成长篇论文，大型项目部署，任务完成虚拟助手，和知识嵌入式系统。这些例子展示了该框架如何帮助用户更轻松地控制语言模型完成复杂的任务。与传统的人类语言模型交互相比，Low-code LLM具有以下优点：</p>
<ol>
<li>可控制的生成结果。复杂的任务被分解为具有结构紧凑的布局，并且对用户可控制</li>
</ol></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><ol start="2">
<li>Friendly Interaction.</li>
</ol>
<p>The intuitive workﬂow enables users to swiftly comprehend the LLMs’ execution logic, and the low-code operation through a graphical user interface empowers users to conveniently modify the workﬂow in a user-friendly manner. In this way, time-consuming prompt engineering is mitigated, allowing users to efﬁciently implement their ideas into detailed instructionsto achieve high-quality results.</p>
<ol start="3">
<li>Wide applicability. The proposed framework can be applied to a wide range of complex tasks across various domains, especially in situations where human’s intelligence or preference areindispensable.</li>
</ol>
<p>2 Low-code LLM </p>
<p>2.1 Overview Figure 1 demonstrates the overview framework of the Low-code LLM. Different from conventional prompt engineering, in Low-code LLM, users ﬁrst input a task prompt, which could be a very brief description of the task they want to achieve. Then, a Planning LLM will design a workﬂow for completing the task. The workﬂow is a kind of structured plan, including execution procedure and jump logic. The user will then edit the workﬂow using six pre-deﬁned low-code visual programming 2 Table 1: Format of workﬂow. For each item, it consists of two parts: execution procedure (i.e. step name and description), and jump logic (null for sequential execution). STEP 1: [Step Name] [Step Description] [[[If ...][Jump to STEP...]][...]] STEP 2: [Step Name] [Step Description] [[[If ...][Jump to STEP...]][...]] · · · operations. After being conﬁrmed by the user, the workﬂow will be interpreted into natural language and inputted to the Executing LLM. The Executing LLM will generate a response with the user’sguide.</p>
<p>Table 2: A workﬂow generated by Planing LLM when the user inputs "Write an essay titled ’Drunk Driving As A Social Issue’". STEP 3 is appointed by the user to provide a more detailed sub-workﬂow. STEP Step Name Step Description Jump Logic STEP 1 Research Gather information on drunk driving as a social issue, including statistics, causes, and effects STEP 2 Outline Organize the information and ma terials into an outline, including an introduction, body, and conclusion If lack of materials, jump to STEP 1 STEP 3 Write Write the essay, including an intro duction that deﬁnes drunk driving as a social issue, a body that discusses the causes and effects of drunk driv ing, and a conclusion that empha sizes the importance of addressing this issue STEP 3.1 Write the introduction Write an introduction that provides background information on drunk driving as a social issue and clearly states the purpose of the essay STEP 3.2 Write the body Write the body of the essay, in cluding paragraphs that discuss the causes and effects of drunk driving, as well as any relevant statistics or research STEP 3.3 Write the conclusion Write a conclusion that summarizes the main points of the essay and em phasizes the importance of address ing drunk driving as a social issue STEP 4 Proofread Check the essay for spelling and punctuation errors 2.2 Planning LLM and Structured Planning Workﬂow A structured planning workﬂow is designed by the Planning LLM based on user input task prompt. Generally, the workﬂow consists of multiple steps and jump logic between steps. To facilitate the transformation from a workﬂow in natural language to an intuitive graphical ﬂowchart, Planning LLM is instructed to produce structured workﬂows, as shown in Table 1, with every step consisting 3 of two parts: (1) Step: including step name and step description that users can directly revise; (2) Jump logic. Additionally, users can extend every step of the workﬂow into a sub-workﬂow with more details according to their preferences, and keep extending until reaching their desired level of detail. We implement the Planning LLM with ChatGPT and educate it to draft a plan with education prompts, which consists of (1) Role of Planning LLM: a powerful problem-solving assistant that provides a standard operating procedure (i.e., workﬂow) for the user’s task; (2) Generation of overall workﬂow: Planning LLM is instructed to analyze the task and provide standard operating procedure as guidance, but is not required actually to solve the task; (3) Generation of sub-workﬂow: If a user wants to extend a step, the Planning LLM is provided with the dialogue history of the previous generation of the overall workﬂow to ensure logical consistency and prevent duplication of content between the sub-workﬂow the other steps of the overall workﬂow. (4) Basic rules: Planning LLM must followthe instructions and be strict to the output format deﬁned in Table 1.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><ol start="2">
<li>友好交互。</li>
</ol>
<p>直觉工作流程使用户可以快速理解LLM执行逻辑， Low-code操作通过图形用户界面使用户轻松地修改工作流程。由此，消耗时间的提示工程减少，使用户可以有效地将其想法转化为详细的指示以达到最佳结果。</p>
<ol start="3">
<li>广泛适用性。建议框架可用于各种领域广泛的复杂任务，特别是在人类智力或喜好不可替代的情况下。</li>
</ol>
<h1>2低代码 LLM</h1>
<p>2.1概述</p>
<p>图1展示了低代码 LLM 的概述框架。与传统的提示工程不同，在 Low-code LLM 中，用户首先输入一个任务提示，这可能是他们要达成的任务的简要描述。然后，A Planning LLM 将设计一个工作流程来完成该任务。工作流程是一种结构化规划，包括执行程序和跳跃逻辑。用户将使用六个预定义的低代码视觉编程2Table 1：工作流程格式。每个对象由执行程序和跳跃逻辑组成，如顺序执行时为空。一旦用户确认，工作流程将转换为自然语言，并将其输入到 executed LLM。executed LLM 将为用户提供指导。</p>
<p>Table 2：当用户输入“写一篇关于” drunk driving 作为一种社会问题的文章“”时生成工作流程。步骤3由用户指定，以提供更深入的子工作流程。步骤。 Step Name Step Description Jump Logic Step 1 Research 收集关于 drunk driving作为一种社会问题的信息，包括统计数据、原因和影响。 </p>
<p>Step 2 大纲组织信息和思想为大纲，包括概述、主体和结论。 </p>
<p>If 缺乏资料， jump to STEP 1 </p>
<p>Step 3 撰写文章，包括定义 Dr driving 作为一种社会问题的概述，讨论 Dr driving 的原因和影响，并强调解决 Dr driving 作为一种社会问题的重要性。</p>
<p>Step 3.1 撰写概述撰写概述，提供关于 Dr driving 作为一种社会问题的背景信息和论文目的。</p>
<p>Step 3.2 撰写主体撰写论文的主体部分，包括讨论 Dr driving 的原因和影响 paragraph 以及任何相关的统计数字或研究。</p>
<p>Step 3.3 撰写结论撰写结论，总结论文的主要观点，强调解决 Dr driving 作为一种社会问题的重要性。</p>
<p>Step 4 校对检查论文的拼写和标点错误 2.2 Planning LLM 和结构化规划工作流程</p>
<p>结构化规划工作流程是由 planning LLM 根据用户输入的任务提示生成的。通常，工作流程由多个步骤和跳跃逻辑在步骤之间组成。为了从自然语言工作流程到直观的图形流charts化，指导 planning LLM 产生结构化工作流程，如图1所示，每个步骤由两个部分：(1)步骤：包括用户可以直接修改的步骤名称和步骤描述；(2)跳跃逻辑。此外，用户可以根据其喜好将其工作流程每个步骤扩展成更详细的子工作流程，并继续扩展，直到达到所需的细节水平。我们使用 ChatGPT 实现 planning LLM 并教育它使用教育提示来编写计划，其中(1)作为 planning LLM 的作用：一个强大的问题解</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>With the education prompts, table 2 exhibits an example of a workﬂow for the task "Write an essay titled ’Drunk Driving As A Social Issue’" generated by the Planning LLM. 2.3 Low-code Interaction with Planning Workﬂow To more intuitively present users with the workﬂow, a ﬂowchart is utilized to visualize the workﬂow and presented it to users. The structured workﬂow (e.g., workﬂow in Table 2) can be conveniently converted to a ﬂowchart. Then, low-code visual programming operations enable users to easily implement sequential execution, conditional execution, and recursive execution. As shown in Figure 2, there are six pre-deﬁned low-code interactions on graphical ﬂowchart. We deﬁne six types of low-code interactions for users to edit the workﬂow, including: • Adding/removing steps by clicking buttons; • Modifying step names or descriptions by clicking and text editing; • Adding/removing a jump logic by clicking; • Changing the processing order by dragging; • Extending a step in the ﬂowchart by clicking the button; • Regeneration, and conﬁrmation by clicking buttons. These operations can be efﬁciently completed in a graphical user interface to achieve a very user-friendly interaction.</p>
<p>2.4 Executing LLM The modiﬁed ﬂowchart is converted back to a natural language based workﬂow (referred to as modiﬁed workﬂow) so that it can be understood by LLMs. Executing LLM is designed to generate responses by following the user-conﬁrmed workﬂow and engaging in interactions with users via a conversational interface. Thanks to the user’s explicit conﬁrmation of the task execution logic in the workﬂow, the results generated by LLMs will be more controllable and satisfactory. We implement the Executing LLM with ChatGPT and educate it to generate responses by providing it with education prompts, which instruct the ChatGPT to generate responses by strictly following theprovided workﬂow.</p>
<p>2.5 Application Scenarios We believe that, no matter how powerful large language models will be in the future, some tasks inevitably require users’ participation. For example, users need to communicate their ideas and preferences, their understanding of the task, and their desired output format to the large language models. The traditional approach is to iterate through cumbersome prompt engineering, but the interaction method of Low-code LLM will greatly liberate users from such tedious prompt engineering. Workﬂow is an effective intermediate language that both humans and large language models can understand. This simple low-code operation in graphical user interface allows users to easily complete their logical ideas, while the structured planning process allows large language models to executetasks more strictly according to the logic.</p>
<p>4 Figure 2: Six kinds of pre-deﬁned low-code operations: (1) adding/removing steps; (2) modifying step name or descriptions; (3) adding/removing a jump logic; (4) changing the processing order; (5)extending a part of the ﬂowchart; (6) regeneration and conﬁrmation.</p>
<p>5</p>
<p>3 Experiments </p>
<p>3.1 Experimental Setup We demonstrate the power and potential of Low-code LLM in assisting users with four categories of tasks: (1) Long Content generation, including long texts (such as blogs, business plans, and papers), and posters, wherein users interact with the ﬂowchart generated by the Planning LLM to specify thestructure, idea, and focus of the generation.</p>
<p>(2) Large Project Development, including complex object relations and system design. Users can educate LLMs about their architect design through low-code interactions. (3) Task-completion Virtual assistant, where developers can predeﬁne the interaction logic between the virtual assistant and customers by editing the ﬂowchart, and the Executing LLM will strictly follow the logic speciﬁed by the developer to minimize potential risks. (4) Knowledge-embedded system, where domain experts can embed their experience or knowledge into a conducting workﬂow. Then, the counseling assistant will follow a pre-deﬁned pattern and actas a coach to scaffold users to complete their tasks.</p>
<p>In particular, the Low-code LLM experiments are carried out using the OpenAI service (gpt-3.5 turbo). In each experiment, we detail the user-deﬁned requirements, the user-provided input prompt, the ﬂowchart created by the Planning LLM, user edits on the ﬂowchart, and the ﬁnal generationresults.</p>
<p>In the qualitative analysis, we examined four pilot cases in the above categories to demonstrate the beneﬁts of Low-code LLM in achieving controllable and satisfactory results. All codes will bereleased for reproduction.</p>
<p>3.2 Qualitative Analysis Pilot Case 1: Essay Writing As shown in Figure3, by enabling users to make speciﬁc edits to the ﬂowchart, users can easily communicate with the system on their ideas and writing structures. As a result, the generated results are very controllable and highly aligned with users’ writing plans. Low-code interaction is a win-win collaboration of the user’s intelligence and LLM’s powerful textgeneration ability.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>随着教育提示的出现，表2展示了由规划语言模型生成的“撰写一篇题为 ’酗酒作为社会问题’ 的作文”的任务的工作流程示例。2.3低代码交互与规划Workflow
为了更直观地显示用户与流程的互动，使用图谱来表示流程，并通过这些信息向用户展示流程。可以使用流程图(如表2中的流程图)将其转换为流程图。然后，低代码可视化编程操作使用户轻松地实现并发执行、条件执行和递归执行。如图2所示，流程图上列出了六个预定义的低代码交互。我们定义了用户 edit workflow  six 種類別，包括：•点击 buttons 添加/移除步驟；•使用click and text edit 修改步驟名稱或描述；•使用click 將跳轉執行；•拖動更改处理顺序；•使用click 在流程图中添加/移除步驟；•使用click 生成和确认。这些操作可以在图形用户界面上高效完成，以实现直观的交互。</p>
<p>2.4执行 LLM
经修改的流程图转换为基于自然语言的流程图(称为修改后的流程图)，以便用户可以理解和解释。执行 LLM 旨在通过遵循用户确认的流程和与用户进行交互来生成响应。由于用户对工作流程中的任务执行逻辑的明确确认，LLM 生成的响应将更加可控和一致。我们在执行执行 LLM 的过程中使用 ChatGPT，并通过它向它提供教育提示，以使其生成响应。教育提示以特定的模式引导 ChatGPT，并作为指导者帮助用户完成任务。</p>
<p>2.5应用场景
我们相信，无论未来大型语言模型的力量如何，某些任务不可避免地需要用户参与。例如，用户需要将自己的思想和偏好、任务理解以及所需的输出格式传达给大型语言模型。传统的方法通常是通过多次Prompt工程迭代实现，但 Low-code LLM 的交互方法将大大解放用户的prompt工程。流程是一种有效的中间语言，人类和大型语言模型都能理解和使用。图形用户界面中的简单低代码操作使用户能够轻松完成他们的逻辑想法，而结构化工作计划使大型语言模型能够更严格地按照逻辑执行任务。</p>
<p>图2：六种预定义的低代码操作：(1)添加/移除步；(2)修改步名或描述；(3)添加/移除跳</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>Pilot Case 2: Object-oriented Programming Even though large language models demonstrate signiﬁcant capabilities in code generation, it can be challenging for users to precisely instruct their requirements to an LLM in building complex systems. However, as shown in Figure 4, Low-code LLM enables professional programming architects to easily input their system design through low code interaction. The results verify that the generated codes strictly follow the expert’s design. With the Low-code LLM interaction, constructing a complex system becomes much more convenient forusers.</p>
<p>Pilot Case 3: Virtual Hotel Service Figure 5 shows the advantages of Low-code LLM over traditional prompt engineering for implementing a task-completion virtual assistant. By using Low code LLM, users, probably hotel managers, can take advantage of a structured planning ﬂowchart and interactively deﬁne the necessary execution logic for the virtual assistant. This ensures that the virtual assistant operates according to the managers’ exact intentions, reducing potential errors and misbehavior. The intuitive, visual nature of the ﬂowchart allows for easy editing and modiﬁcation, and the result shows the behaviors are tightly aligned with the speciﬁed requirements. Pilot Case 4: Resume Helper Figure 6 shows another scenario where Low-code LLM is helpful. In some professional, knowledge-driven scenarios, experts can integrate execution logic and knowledge into the workﬂow through low-code interactions. By embedding expert knowledge, users can be scaffolded to complete their tasks. In this case, a human resource expert inputs resume creation experiences into Resume Helper, and when users use it to complete their resumes, the Executing LLM strictly follows the expert-deﬁned workﬂow to communicate with users. Some similar scenarios may include psychological counseling, medical diagnosis, mock interviews, and others. 6 Low-code Figure 3: Essay Generation through Low-Code LLM: Users interact with the LLM by editing a ﬂowchart, resulting in responses that are more closely aligned with their requirements. The red section in the ﬂowchart illustrates how users modify the workﬂow. The generated output is highly tailored to the user’s speciﬁc needs (see the highlighted parts). To obtain similar controllable results, conventional prompt engineering requires complex prompt and heavy prompt modiﬁcation works. 7 Low-code Figure 4: This case demonstrates how to empower LLMs coding using object-oriented programming patterns via the proposed approach. Architecture design is a professional skill for deveoping large scale project. With Low-code LLM, architects can easily educate the model about well-designed architecture, allowing Executing LLM to generate code based on ﬂowcharts. The results from ChatGPT performed poorly in object design. After incorporating a human-edited workﬂow, themodel was able to generate correct codes.</p>
<p>8 Low-code Figure 5: A virtual hotel service using Low-code LLM allows users, such as hotel managers, to clearly deﬁne the execution logic through interaction with the structured planning ﬂowchart, ensuring that the conduction logic strictly follows the user’s intent. The red part in the ﬂowchart shows how the user edits the workﬂow. As a result, the generated system is highly aligned with the user’s speciﬁed requirements (refer to the highlighted part). Without the low-code LLM interaction, it becomes difﬁcult to control how virtual hotel service communicates with customers. 9 Low-code Figure 6: Resume Helper via Low-code LLM. In this case, domain experts, maybe human resource experts, can embed their resume-creating knowledge into a workﬂow. With the embedding of expert knowledge, Executing LLM can scaffold users to complete their resumes. Similar examples may also include psychological counseling, medical diagnosis, interview mock, etc. 10</p>
<p>4 Related Works </p>
<p>4.1 Large Language Models Large language models (LLMs) have emerged as a prominent area of research in recent years, thanks to advances in deep learning, natural language processing, and powerful computational infrastructure. LLMs are deﬁned by their signiﬁcant model size, capacity to understand and generate human-liketext, and ability to generalize across different tasks and applications.</p>
<p>Recent LLMs, such as GPT-4 and ChatGPT, have made impressive strides in generating more coherent and contextually relevant responses. They have been applied in various industries and ﬁelds, including content creation, code development(Chen et al., 2021), customer support(George and George, 2023), and more. However, while LLMs have demonstrated promising potential, they still face limitations(Bowman, 2023; Borji, 2023; Bang et al., 2023). In particular, controlling the behavior and output of LLMs for complex tasks remains a challenge, which has led to the development of new techniques, such as prompt engineering, and methods to improve results(Wu et al., 2023; Ge et al.,2022; Wu et al., 2022; Shen et al., 2023).</p>
<p>4.2 Prompt Engineering Prompt engineering has emerged as an essential technique for interacting with LLMs to achieve desired outcomes. The success of large language models relies heavily on their ability to produce answers to various queries(Zuccon and Koopman, 2023). However, providing effective prompts that convey the exact intent of humans is a non-trivial task, especially when it comes to complex tasksand requirements.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>实验案例2：面向对象的编程</p>
<p>尽管大型语言模型(LLMs)在代码生成方面表现出极大的能力，但对用户而言，在构建复杂系统时精确地指导他们的需求可能新的挑战。然而，如图4所示，低代码(Low-code)LLM使专业编程建筑师通过低代码互动非常方便地输入系统设计方案。结果证明，生成的代码严格遵守专家设计的规范。通过低代码交互，构建复杂系统变得更加方便。</p>
<p>实验案例3：虚拟酒店服务</p>
<p>图5展示了传统提示工程(prompt engineering)与低代码LLM之间的Advantages。通过使用低代码LLM，用户(可能是酒店经理)可以利用结构化规划流程图进行交互，以定义虚拟助手的必要执行逻辑。这样以确保虚拟助手按照经理精确的意图运行，降低了潜在的错误和副作用。流程图的直观性、可视化使得修改和扩展变得容易，结果是行为与所需规范非常紧密地一致性。</p>
<p>实验案例4：求职助手</p>
<p>图6显示了低代码LLM在这种情境下有所帮助的情况。在一些专业的、知识驱动的情境中，专家可以通过低代码交互集成执行逻辑和知识到工作流程中。通过嵌入 expert 知识，用户可以被激励完成他们的工作。在这种情况下，人力资源专家将 resume Helper 中的 resume 创建经验输入到 resume Helper中，当用户用它填写简历时，执行 LLM 会严格遵循专家定义的工作流程与客户进行交互。一些类似的场景可能包括心理 counseling、医学诊断、面试模拟等。</p>
<p>实验案例5：使用低代码LLM的虚拟酒店服务</p>
<p>图8显示了使用低代码LLM的虚拟酒店服务的优势。当用户(可能是酒店经理)通过编辑流程图与 LLM 交互时，LLM 根据用户的特定需求进行行为调整。流程图的红色部分展示了如何用户修改工作流程。生成的输出高度定制，以用户的特定需求为中心(请参阅参阅Highlight部分)。要获得类似的可控制结果，传统的提示工程需要繁琐的提示和修改工作。</p>
<p>实验案例6：使用低代码LLM的求职助手。在这种情况下，域专家(可能是人力资源专家)可以将他们的简历创建知识嵌入到工作流程中。通过嵌入 expert 知识，执行 LLM 可以激励用户完成他们的工作任务。类似情况还包括的心理 counseling、医学诊断、面试模拟等。</p>
<h1>相关的工作</h1>
<p>4.1 大型语言模型</p>
<p>近年来，大型语言模型(LLMs)已成为研究的重点，得益于深度学习、自然语言处理和强大的计算基础设施的发展。LLMs的定义基于其巨大的模型大小、理解和生成人类文本的能力以及在多种任务和应用程序中可泛化的能力。</p>
<p>最近的 LLMs，例如 GPT-4 和 ChatGPT 取得了令人瞩目的成就，在生成更连贯和上下文相关的响应方面。这些应用广泛适用于内容创作、代码开发(Chen et al.,2021)、客户服务(George and George,2023)等不同的领域。然而，尽管 LLMs表现出了令人沮丧的潜在成功，但它们仍然面临着限制( Bowman,2023; Borji,2023; Bang et al.,2023)。尤其重要的是，控制 LLMs 执行逻辑在复杂任务上的难度仍然是一个挑战，这导致开发新的技术方法，例如提示工程，以及改进结果的方法(Wu et al.,2023;Ge et al.,2022; Wu et al.,2022; Shen et al.,2023)。</p>
<p>4.2 提示工程</p>
<p>提示工程作为一种与 LLM 进行交互以实现预期结果的必不可少的技术，已成为研究的焦点。大型语言模型的成功在很大程度上取决于其在各种查询中所能提供的答案( Zuccon 和 黄波，2023)。然而，要提供表示人类精确的 intent 的有效提示，尤其是当涉及到复杂的任务和需求时，是一项非易的任务。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>The challenge in prompt engineering lies in crafting prompts that can manipulate the LLM into generating speciﬁc outcomes. These prompts can vary from simple queries to more complicated instructions requiring the LLM to analyze, reason, and produce creative solutions. Researchers have explored various techniques to simplify prompt engineering, ranging from giving explicit instructions to providing context for LLMs to understand the desired output better(White et al., 2023). Some recent advancements in prompt engineering include techniques such as few-shot learning(Brown et al., 2020; Min et al., 2022), reinforcement-learning(Deng et al., 2022). These approaches aim at enabling LLMs to provide more accurate responses based on the user’s needs. However, these techniques often demand substantial expertise and time, making it difﬁcult for end-users to leveragethe full potential of these LLMs.</p>
<p>The Low-code LLM framework proposed in our paper provides an innovative solution by involving the users in the process of designing workﬂows, which ultimately controls the LLM’s response generation. This approach aims at eliminating the complexity in prompt engineering and streamlines the process by allowing users to control intermediate steps and preferences in a more user-friendly way. By doing so, Low-code LLM fosters more transparent and controllable human-LLM collaboration. 4.3 Task Automation with LLMs Recently, various research studies have focused on leveraging large language models for task automa tion(Auto-GPT, 2023; Liang et al., 2023; Kim et al., 2023). Task automation with LLMs usually involves the model analyzing a given input, breaking it down into subtasks, and generating desired outputs accordingly. The success of task automation with LLMs beneﬁts from the models’ ability tounderstand the context and generate coherent responses.</p>
<p>However, the black-box nature of the interaction and the difﬁculty in controlling their output have remained signiﬁcant challenges in deploying LLMs for complex tasks(Tan et al., 2023). Users often face difﬁculties when attempting to direct LLMs to adhere to speciﬁc requirements or constraints, and generating satisfactory outputs often involves time-consuming iterations. The proposed Low-code LLM framework involves users in the interaction process and improving controllability over generated outputs. By offering a user-friendly and efﬁcient way of specifying preferences and constraints, the Low-code LLM framework contributes to research on task automation with LLMs, while further bridging the gap between human users and LLMs for achieving morestructured and ﬁne-grained control.</p>
<p>11</p>
<p>5 Limitations </p>
<p>While the Low-code LLM framework promises a more controllable and user-friendly interaction withlarge language models, there are some limitations.</p>
<p>One such limitation is the increase in the cognitive load for users, who now need to understand andmodify the generated workﬂows.</p>
<p>Furthermore, accurate and effective structured planning within the Planning LLM may be challeng ing, and bad structured planning poses a heavy user editing burden. But we believe with the evolution of LLMs and research on task automation, the planning ability will be getting satisfactory. Lastly, the current design assumes that users have sufﬁcient domain knowledge and skills to modifyand conﬁrm the generated workﬂows effectively.</p>
<p>6 Looking Forward </p>
<p>There are various promising and interesting directions for Low-code LLM: Integration with Task Automation: There are many types of research on task automation, plan making(Wang et al., 2023) and tool utilization(Liang et al., 2023; Nakano et al., 2021) by LLMs. As the planning ability and skill sets of LLMs become more powerful, user intervention in low code interaction will decrease. However, low-code interaction still provides users a friendly way to make some simple edits and conﬁrm the LLM execution logic. Meanwhile, the edited or conﬁrmedworkﬂow can be a valuable resource for improving task automation.</p>
<p>Cross-Platform Integration: Low-Code LLM has the potential to integrate with a wide range of platforms, allowing users to conveniently implement these systems across numerous applications and tools. As a versatile interaction pattern, Low-Code LLM is not limited to language models but can beemployed in various cross-modality human-computer interactions.</p>
<p>Expansive Application Scenarios: This paper presents four pilot cases, and we believe that Low-Code LLM can be widely applied across scenarios. There will always be situations where human opinion or information is important, and Low-Code LLM offers an effective interaction framework for easyhuman-LLM collaboration.</p>
<p>7 Conclusion </p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>在提示工程的挑战在于编写可以操纵的语言模型生成特定结果的提示。这些提示可以是简单的查询，也可以是更复杂的任务指令，需要语言模型来分析、推理和产生创意解决方案。研究人员已经探索了许多方法简化提示工程，从给出明确的指令到为语言模型提供上下文以更好地理解预期输出(White et al., 2023)。最近的进展之一是语言模型任务自动化，如短期学习(Brown et al., 2020; Min et al., 2022)和强化学习(Deng et al., 2022)。这些方法旨在使语言模型根据用户的需求提供更准确的回答。然而，这些技术通常需要大量的专业知识和经验，使得最终用户难以充分利用这些语言模型的潜力。</p>
<p>在本文中提出的低代码语言模型框架通过让用户参与到设计工作流程的过程，最终控制语言模型的响应生成，旨在消除提示工程的复杂性，并简化过程，通过让用户更直观地控制中间步骤和偏好来实现。通过这种方式，低代码语言模型促进了更透明和可控的人类-语言模型协作。4.3 任务自动化与语言模型</p>
<p>虽然目前低代码语言模型框架 promises a more controllable和用户友好的操作与大型语言模型，但有些限制。</p>
<p>有一种限制是用户的认知负担增加，现在用户需要理解和修改生成的任务脚本。</p>
<p>此外，预测和有效的结构规划在规划语言模型时可能变得困难，而 bad 结构规划则给用户编辑工作带来了艰巨负担。但我们相信随着语言模型的演变和任务自动化的研究，规划能力将得到改进。最后，目前的设计假定用户可以有效地修改和确认生成的任务脚本。</p>
<p>跨平台集成：低代码语言模型具有与广泛平台集成的潜力，使得用户可以轻松地在各种不同的应用程序和工具之间实现这些系统。作为一种多模态交互模式，低代码语言模型不局限于语言模型，而是可以用于各种跨模态的人机交互。</p>
<p>广泛的应用场景：本文提出了四个示范案例，我们相信低代码语言模型可以在各个场景中广泛使用。将永远存在一些需要人类意见或信息的情况，而低代码语言模型提供了一个易用的写作框架，实现与语言模型的轻松人类合作。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>This paper introduced a novel human-LLM interaction framework called Low-code LLM, which aims to improve the control and efﬁciency of utilizing large language models for complex tasks. Low-code LLM allows users to better understand and modify the logic and workﬂow underlying the LLMs’ execution of instructions. The demonstration cases reveal the advantages of our approach, including stronger control over LLMs, a user-friendly interaction and wide applicability. Compared with prompt engineering, the proposed Low-code LLM framework advances the state-of-the-art in human-LLM interactions by bridging the gap of communication and collaboration between humans and LLMs. We believe the Low-code LLM framework presents a promising solution to many of the challenges faced by LLM users today and has the potential to greatly impact a wide range ofindustries and applications.</p>
<p>Acknowledgment </p>
<p>Part of this paper has been collaboratively crafted through interactions with the proposed Low-code LLM. The process began with GPT-4 outlining the framework, followed by the authors supplementing it with innovative ideas and reﬁning the structure of the workﬂow. Ultimately, GPT-4 took charge ofgenerating cohesive and compelling text.</p>
<p>References </p>
<p>OpenAI. Chatgpt, 2022. URL https://openai.com/blog/chatgpt. 12 OpenAI. Gpt-4 technical report, 2023. Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artiﬁcial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023. Harsha Nori, Nicholas King, Scott Mayer McKinney, Dean Carignan, and Eric Horvitz. Capabilities of gpt-4 on medical challenge problems. arXiv preprint arXiv:2303.13375, 2023. Jonathan H Choi, Kristin E Hickman, Amy Monahan, and Daniel Schwarcz. Chatgpt goes to lawschool. Available at SSRN, 2023.</p>
<p>David Baidoo-Anu and Leticia Owusu Ansah. Education in the era of generative artiﬁcial intelligence (ai): Understanding the potential beneﬁts of chatgpt in promoting teaching and learning. Availableat SSRN 4337484, 2023.</p>
<p>Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan,and Jimmy Ba.</p>
<p>Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022. Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen, and Guilin Qi. Evaluation of chatgpt as a question answering system for answering complex questions. arXiv preprintarXiv:2303.07992, 2023.</p>
<p>Martin Hirzel. Low-code programming models. arXiv preprint arXiv:2205.02282, 2022.Microsoft.</p>
<p>Visual basic, 1991. URL https://learn.microsoft.com/en-Us/dotnet/visual-basic/getting-started/.</p>
<p>Mitchel Resnick, John Maloney, Andrés Monroy-Hernández, Natalie Rusk, Evelyn Eastmond, Karen Brennan, Amon Millner, Eric Rosenbaum, Jay Silver, Brian Silverman, et al. Scratch: programmingfor all. Communications of the ACM, 52(11):60–67, 2009.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>这篇论文提出了一种新的人类 - 语言模型交互框架，称为低代码语言模型(Low-code LLM)，旨在提高使用大型语言模型进行复杂任务的控制和效率。低代码语言模型允许用户更好地了解和修改语言模型执行指令的逻辑和工作流程。演示案例揭示了我们方法的优势，包括对语言模型的控制加强、用户友好性和广泛的应用范围。与提示工程相比，提议的低代码语言模型框架通过跨越人类和语言模型之间的沟通和协作差距，提高了人类 - 语言模型交互方面的最先进的水平。认为 Low-code LLM 框架解决了许多语言模型用户目前面临的挑战，并有可能对各种类型的行业和应用产生重大影响。</p>
<h1>致谢</h1>
<p>本文一部分是通过与提议的低代码语言模型交互来共同构建的。过程始于 GPT-4 制定框架，接着作者加入了创新想法并改进 workflow 的结构。最终，GPT-4 负责生成连贯和引人注目的文本。</p>
<h1>References</h1>
<p>OpenAI. Chatgpt, 2022, <a href="https://openai.com/blog/chatgpt/">https://openai.com/blog/chatgpt/</a>. OpenAI. Gpt-4 技术报告，2023,<a href="https://openai.com/blog/chatgpt/">https://openai.com/blog/chatgpt/</a>. Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023. Harsha Nori, Nicholas King, Scott Mayer McKinney, Dean Carignan, and Eric Horvitz. Capabilities of gpt-4 on medical challenge problems. arXiv preprint arXiv:2303.13375, 2023. Jonathan H Choi, Kristin E Hickman, Amy Monahan, and Daniel Schwarcz. Chatgpt goes to lawschool. SSRN, 2023.</p>
<p>David Baidoo-Anu and Leticia Owusu Ansah. Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning. SSRN 4337484, 2023.</p>
<p>Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba.</p>
<p>Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022. Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen, and Guilin Qi. Evaluation of chatgpt as a question answering system for answering complex questions. arXiv preprint arXiv:2303.07992, 2023.</p>
<p>Martin Hirzel. Low-code programming models. arXiv preprint arXiv:2205.02282, 2022. Microsoft.</p>
<p>Visual basic, 1991, <a href="https://learn.microsoft.com/en-us/dotnet/visual-basic/getting-started/">https://learn.microsoft.com/en-us/dotnet/visual-basic/getting-started/</a>.</p>
<p>Mitchel Resnick, John Maloney, Andrés Monroy-Hernández, Natalie Rusk, Evelyn Eastmond, Karen Brennan, Amon Millner, Eric Rosenbaum, Jay Silver, Brian Silverman, et al. Scratch: programming for all. Communications of the ACM, 52(11):60–67, 2009.</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021. A Shaji George and AS Hovan George. A review of chatgpt ai’s impact on several business sectors. Partners Universal International Innovation Journal, 1(1):9–23, 2023.Samuel R Bowman.</p>
<p>Eight things to know about large language models. arXiv preprint arXiv:2304.00612, 2023. Ali Borji. A categorical archive of chatgpt failures. arXiv preprint arXiv:2302.03494, 2023. Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023, 2023. Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Vi sual chatgpt: Talking, drawing and editing with visual foundation models. arXiv preprint arXiv:2303.04671, 2023. Tao Ge, Jing Hu, Li Dong, Shaoguang Mao, Yan Xia, Xun Wang, Si-Qing Chen, and Furu Wei. Extensible prompts for language models. arXiv preprint arXiv:2212.00616, 2022. Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: Chaining large language model prompts through visual programming. In CHI Conference on Human Factors in Computing Systems Extended Abstracts, pages 1–10,2022.</p>
<p>Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580,2023.</p>
<p>13 Guido Zuccon and Bevan Koopman. Dr chatgpt, tell me what i want to hear: How prompt knowledge impacts health answer correctness. arXiv preprint arXiv:2302.13793, 2023. Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith, and Douglas C Schmidt. A prompt pattern catalog to enhance promptengineering with chatgpt. arXiv preprint arXiv:2302.11382, 2023.</p>
<p>Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners, 2020. Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. Rethinking the role of demonstrations: What makes in-context learning work?, 2022. Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing, and Zhiting Hu. Rlprompt: Optimizing discrete text prompts with reinforcementlearning, 2022.</p>
<p>Auto-GPT. Auto-gpt, 2023. URL https://github.com/Significant-Gravitas/Auto-GPT. Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, et al. Taskmatrix. ai: Completing tasks by connecting foundation models withmillions of apis. arXiv preprint arXiv:2303.16434, 2023.</p>
<p>Geunwoo Kim, Pierre Baldi, and Stephen McAleer. Language models can solve computer tasks.arXiv preprint arXiv:2303.17491, 2023.</p>
<p>Dongjie Wang, Chang-Tien Lu, and Yanjie Fu. Towards automated urban planning: When generative and chatgpt-like ai meets urban planning. arXiv preprint arXiv:2304.03892, 2023. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021. 14</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>以下是论文的翻译：</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 评估在代码上训练的大型语言模型。 arXiv预印本消息arXiv:2107.03374, 2021。 </p>
<p>A Shaji George and AS Hovan George。 对几种 business sectors 的 chatgpt 人工智能的审查。  Partners Universal International Innovation Journal, 1(1):9-23, 2023。 Samuel R Bowman。 </p>
<p>以下是一些大型语言模型的相关信息。 arXiv预印本消息arXiv:2304.00612, 2023。 Ali Borji。 一个 chatgpt  fail 的 categorical archive。 arXiv预印本消息arXiv:2302.03494, 2023。 Yejin Bang, Samuel Cahyahya，纳言达·卡巴亚伊，米卡·泰南，董玉莲，陈飞云，吴青峰，郑锡鹏，谢文忠，何景华，李东。 一个多任务、多语言、多模态的 chatgpt 对推理、错觉和互动进行评估。 arXiv预印本消息arXiv:2302.04023, 2023。 </p>
<p>陈飞云，辛玉平，吴青峰，谢文忠，李东。 vual chatgpt: 用图形基础模型进行对话、绘制和编辑。 arXiv预印本消息arXiv:2303.04671, 2023。 </p>
<p>Tao Ge, Jing Hu, Li Dong, Shaoguang Mao, Yan Xia, Xun Wang, Si-Qing Chen, 和 Fu She。 用 chatgpt 的外部提示进行语言模型的扩展。 </p>
<p>摘要</p>
<p>本文研究了如何使用代码训练的大型语言模型。我们回顾了 chatgpt 人工智能在几个 Business sectors 中的影响的评估。我们评估了 chatgpt 在社会、文化和企业等方面的智能应用。论文还探讨了 prompt knowledge 对保持健康回答的正确性的影响。我们还探讨了如何将prompt知识应用于计算机任务中。 </p>
<p>关键词：大型语言模型；代码训练；人工智能；健康；回答；计算机任务；Prompt knowledge, health answer correctness;</p>
<p>摘要</p>
<p>本文研究了如何使用代码训练的大型语言模型。我们回顾了 chatgpt 人工智能在几个 Business sectors 中的影响的评估。我们评估了 chatgpt 在社会、文化和企业等方面的智能应用。论文还探讨了 prompt knowledge 对保持健康回答的正确性的影响。我们还探讨了如何将 prompt knowledge 应用于计算机任务中。</p></div></div>
</div>
        